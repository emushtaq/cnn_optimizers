# comparing_cnn_optimizers
My simple comparison of Adam, Adadelta and SGD optimizers on a CNN based MNIST classifier. Results are visulalized in the folder 'Results'. :)

Tuning the hyperparams and altering the number of epochs and batch size could improv results vastly.
